<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Informer WASM Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #222123;
        }
        h1 {
            color: #c7c7c7;
        }
        .controls {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .control-group {
            margin-bottom: 15px;
        }
        label {
            display: inline-block;
            width: 150px;
            font-weight: bold;
        }
        input[type="number"], input[type="range"] {
            width: 200px;
            padding: 5px;
        }
        button {
            background-color: #4CAF50;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 16px;
            margin-top: 10px;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        .results {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .result-section {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .result-section h2 {
            margin-top: 0;
            color: #4CAF50;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 10px;
        }
        .descriptor {
            display: flex;
            justify-content: space-between;
            padding: 8px;
            border-bottom: 1px solid #eee;
        }
        .descriptor-name {
            font-weight: bold;
            color: #555;
        }
        .descriptor-value {
            font-family: monospace;
            color: #333;
        }
        .status {
            padding: 10px;
            margin-bottom: 20px;
            border-radius: 4px;
            text-align: center;
        }
        .status.loading {
            background-color: #fff3cd;
            color: #856404;
        }
        .status.ready {
            background-color: #d4edda;
            color: #155724;
        }
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
        }
    </style>
</head>
<body>
    <h1>ðŸŽµ Audio Analysis with Informer WASM</h1>
    
    <div id="status" class="status loading">Loading libraries...</div>
    
    <div class="controls">
        <h2>Audio uploader</h2>

         <div class="control-group">
            <label for="audioFile">Upload audio:</label>
            <input type="file" id="audioFile" accept="audio/*">
        </div>
        
        <div class="control-group">
            <label for="fftSize">FFT Size:</label>
            <select id="fftSize">
                <option value="512">512</option>
                <option value="1024">1024</option>
                <option value="2048">2048</option>
                <option value="4096" selected>4096</option>
                <option value="8192">8192</option>
            </select>
        </div>
        
        <button id="analyzeBtn" disabled>Analyze Audio</button>
    </div>

    <div id="descriptor-legend"></div>
    <div class="result-section" style="margin-top: 20px;">
        <h2>ðŸ“ˆ Time-Frequency Analysis</h2>
        <canvas id="analysisCanvas" style="width: 100%; height: 400px; background: white; border: 1px solid #ddd; border-radius: 4px;"></canvas>
    </div>
    
    <!-- Load your compiled Informer WASM -->
    <script src="informer.js"></script>
    
    <script>
        let InformerLib = null;
        let isReady = false;
        
        const statusDiv = document.getElementById('status');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const timeResults = document.getElementById('timeResults');
        const freqResults = document.getElementById('freqResults');
        const audioFileInput = document.getElementById('audioFile');
        const canvas = document.getElementById('analysisCanvas');
        const ctx = canvas.getContext('2d');
        
        // Load Informer WASM module
        InformerModule().then(Module => {
            InformerLib = Module;
            isReady = true;
            statusDiv.textContent = 'âœ“ Libraries loaded and ready!';
            statusDiv.className = 'status ready';
            analyzeBtn.disabled = false;
            console.log('Informer WASM library loaded successfully');
        }).catch(error => {
            statusDiv.textContent = 'âœ— Error loading Informer library';
            statusDiv.className = 'status error';
            console.error('Failed to load Informer:', error);
        });
        
        // Generate audio signal
        function generateSignal(waveform, frequency, sampleRate, duration) {
            const samples = Math.floor(sampleRate * duration);
            const buffer = new Float64Array(samples);
            
            for (let i = 0; i < samples; i++) {
                const t = i / sampleRate;
                const phase = 2 * Math.PI * frequency * t;
                
                switch(waveform) {
                    case 'sine':
                        buffer[i] = Math.sin(phase);
                        break;
                    case 'square':
                        buffer[i] = Math.sin(phase) >= 0 ? 1 : -1;
                        break;
                    case 'sawtooth':
                        buffer[i] = 2 * (t * frequency - Math.floor(0.5 + t * frequency));
                        break;
                    case 'triangle':
                        buffer[i] = 2 * Math.abs(2 * (t * frequency - Math.floor(0.5 + t * frequency))) - 1;
                        break;
                    case 'noise':
                        buffer[i] = Math.random() * 2 - 1;
                        break;
                }
            }
            
            return buffer;
        }
        
        // Perform FFT and get magnitudes
                // Analyze an audio buffer in overlapping chunks and visualize
                // Global state for visualization
                // Helper: Compute linear-magnitude FFT using OfflineAudioContext
                async function computeFFTMagnitudes(chunk, fftSize, sampleRate) {
            // Ensure input is Float32Array
            const float32Data = new Float32Array(chunk);
            let data;
            if (float32Data.length >= fftSize) {
                data = float32Data.slice(0, fftSize);
            } else {
                data = new Float32Array(fftSize);
                data.set(float32Data);
            }

            // Create offline context
            const OfflineAudioContext = window.OfflineAudioContext || window.webkitOfflineAudioContext;
            const offlineCtx = new OfflineAudioContext(1, fftSize, sampleRate);

            const audioBuffer = offlineCtx.createBuffer(1, fftSize, sampleRate);
            audioBuffer.copyToChannel(data, 0);

            const source = offlineCtx.createBufferSource();
            source.buffer = audioBuffer;

            const analyser = offlineCtx.createAnalyser();
            analyser.fftSize = fftSize;
            analyser.smoothingTimeConstant = 0;

            source.connect(analyser);
            analyser.connect(offlineCtx.destination);
            source.start(0);

            await offlineCtx.startRendering();

            // Get frequency data in dB
            const freqData = new Float32Array(analyser.frequencyBinCount);
            analyser.getFloatFrequencyData(freqData);

            // Convert dB to linear magnitude
            const magnitudes = new Float64Array(freqData.length);
            for (let i = 0; i < freqData.length; i++) {
                if (freqData[i] < -1000) {
                    magnitudes[i] = 0.0;
                } else {
                    magnitudes[i] = Math.pow(10, freqData[i] / 20.0);
                }
            }
            return magnitudes;
        }    

        // Analyze audio buffer and compute multiple descriptors over time
        async function analyzeAudioBuffer(audioBuffer, sampleRate, fftSize) {
            const totalSamples = audioBuffer.length;
            const hopSize = fftSize / 2;
            const numFrames = Math.max(1, Math.floor((totalSamples - fftSize) / hopSize) + 1);

            // Initialize descriptor arrays
            const descriptors = {};
            for (const key of allDescriptorKeys) {
                descriptors[key] = [];
            }

            const times = [];
            const waveform = Array.from(audioBuffer);
            const duration = totalSamples / sampleRate;

            for (let i = 0; i < numFrames; i++) {
                const start = i * hopSize;
                const end = start + fftSize;
                if (end > totalSamples) break;

                const chunk = audioBuffer.slice(start, end);
                const informer = new InformerLib.Informer(sampleRate, 0.85, fftSize);
                
                // Time descriptors
                informer.setBuffer(new Float64Array(chunk));
                informer.computeDescriptors(true, false);
                const timeDesc = informer.getTimeDescriptors();

                // Fill time descriptors (clamp to [0,1] if needed)
                descriptors.peak.push(Math.min(1, Math.abs(timeDesc.peak || 0)));
                descriptors.rms.push(Math.min(1, timeDesc.rms || 0));
                descriptors.variance.push(Math.min(1, timeDesc.variance || 0));
                descriptors.zcr.push(Math.min(1, timeDesc.zcr || 0));

                // Frequency descriptors
                const magnitudes = await computeFFTMagnitudes(chunk, fftSize, sampleRate);
                informer.setMagnitudes(magnitudes);
                informer.computeDescriptors(false, true);
                const freqDesc = informer.getFrequencyDescriptors();

                // Fill frequency descriptors
                descriptors.centroid.push(freqDesc.centroid || 0);
                descriptors.peakFreq.push(freqDesc.peak || 0);
                descriptors.rolloff.push(freqDesc.rolloff || 0);
                descriptors.spread.push(freqDesc.spread || 0);
                descriptors.flatness.push(Math.min(1, Math.max(0, freqDesc.flatness || 0)));
                descriptors.entropy.push(Math.min(1, Math.max(0, freqDesc.entropy || 0)));
                descriptors.irregularity.push(Math.min(2, Math.max(0, freqDesc.irregularity || 0)));
                descriptors.crest.push(freqDesc.crest || 0);
                descriptors.flux.push(Math.min(1, Math.max(0, freqDesc.flux || 0)));
                descriptors.slope.push(freqDesc.slope || 0);
                descriptors.decrease.push(freqDesc.decrease || 0);

                times.push(start / sampleRate);
                informer.delete();
            }

            analysisData = { times, duration, sampleRate, waveform, descriptors };
            drawAnalysis();
            renderDescriptorLegend();
        }

        // Visualization function
                // Visualization function
                // Colors for each descriptor
                const descriptorColors = {
            centroid: '#D32F2F',    // red
            flatness: '#7B1FA2',    // purple
            rms: '#388E3C',         // green
            peak: '#FF6D00',        // orange
            rolloff: '#0288D1',     // blue
            spread: '#5D4037'       // brown
        };

                // Descriptor metadata: name, min, max, unit, category
                const descriptorMeta = {
            // Time Domain
            peak:        { min: 0, max: 1, unit: '',          category: 'time',   label: 'Peak' },
            rms:         { min: 0, max: 1, unit: '',          category: 'time',   label: 'RMS' },
            variance:    { min: 0, max: 1, unit: '',          category: 'time',   label: 'Variance' },
            zcr:         { min: 0, max: 1, unit: '',          category: 'time',   label: 'Zero Crossing Rate' },
            // Skewness/kurtosis time are undefined â€” we'll skip or estimate

            // Frequency Domain
            centroid:    { min: 0, max: 'nyquist', unit: 'Hz', category: 'freq', label: 'Spectral Centroid' },
            peakFreq:    { min: 0, max: 'nyquist', unit: 'Hz', category: 'freq', label: 'Spectral Peak' },
            rolloff:     { min: 0, max: 'nyquist', unit: 'Hz', category: 'freq', label: 'Spectral Rolloff' },
            spread:      { min: 0, max: 'nyquist/2', unit: 'Hz', category: 'freq', label: 'Spectral Spread' },
            flatness:    { min: 0, max: 1, unit: '',          category: 'freq', label: 'Spectral Flatness' },
            entropy:     { min: 0, max: 1, unit: '',          category: 'freq', label: 'Spectral Entropy' },
            irregularity:{ min: 0, max: 2, unit: '',          category: 'freq', label: 'Spectral Irregularity' },
            crest:       { min: 0, max: 10, unit: '',         category: 'freq', label: 'Crest Factor' }, // typical range ~2â€“10
            flux:        { min: 0, max: 1, unit: '',          category: 'freq', label: 'Spectral Flux' },
            slope:       { min: -1, max: 1, unit: '',         category: 'freq', label: 'Spectral Slope' },
            decrease:    { min: -1, max: 1, unit: '',         category: 'freq', label: 'Spectral Decrease' }
            // Skip undefined skew/kurtosis (or treat as 0 if returned)
        };

        const allDescriptorKeys = Object.keys(descriptorMeta);
        let analysisData = null;
        const visibleDescriptors = new Set(['centroid']); // default

        // Vertical mapping helpers
        function freqToY(freq, nyquist, top, height) {
            return top + (1 - freq / nyquist) * height;
        }

        function ampToY(amp, waveOffset, waveHeight) {
            return waveOffset + amp * waveHeight;
        }

        function drawAnalysis() {
            if (!analysisData) return;

            const { times, duration, sampleRate, waveform, descriptors } = analysisData;
            const width = canvas.width = canvas.offsetWidth;
            const totalHeight = canvas.height = 400; // taller canvas

            // Separate visible descriptors by category
            const visibleTime = allDescriptorKeys.filter(k => visibleDescriptors.has(k) && descriptorMeta[k].category === 'time');
            const visibleFreq = allDescriptorKeys.filter(k => visibleDescriptors.has(k) && descriptorMeta[k].category === 'freq');

            const numTracks = visibleFreq.length + visibleTime.length;
            const waveformHeight = 80;
            const trackHeight = numTracks > 0 ? (totalHeight - waveformHeight - 40) / numTracks : 0;
            let currentY = 20; // top margin

            ctx.clearRect(0, 0, width, totalHeight);

            // --- Draw frequency tracks (top) ---
            for (const key of visibleFreq) {
                drawTrack(key, descriptors[key], times, duration, sampleRate, currentY, trackHeight, true);
                currentY += trackHeight;
            }

            // --- Draw time tracks ---
            for (const key of visibleTime) {
                drawTrack(key, descriptors[key], times, duration, sampleRate, currentY, trackHeight, false);
                currentY += trackHeight;
            }

            // --- Draw waveform at bottom ---
            const waveY = totalHeight - waveformHeight;
            drawWaveform(waveform, width, totalHeight, waveformHeight, waveY);
        }

        function drawTrack(key, values, times, duration, sampleRate, y, height, isFreq) {
            const meta = descriptorMeta[key];
            const nyquist = sampleRate / 2;

            // Resolve dynamic max
            let min = meta.min;
            let max = meta.max;
            if (max === 'nyquist') max = nyquist;
            else if (max === 'nyquist/2') max = nyquist / 2;

            // Background
            ctx.fillStyle = '#fafafa';
            ctx.fillRect(0, y, canvas.width, height);

            // Label
            ctx.fillStyle = '#000';
            ctx.font = '12px Arial';
            ctx.textAlign = 'left';
            ctx.fillText(`${meta.label} (${meta.unit})`, 10, y + 15);

            // Grid lines
            ctx.strokeStyle = '#eee';
            ctx.beginPath();
            ctx.moveTo(0, y + height/2);
            ctx.lineTo(canvas.width, y + height/2);
            ctx.stroke();

            // Curve
            if (values.length > 1) {
                ctx.strokeStyle = '#D32F2F';
                ctx.lineWidth = 1.5;
                ctx.beginPath();
                for (let i = 0; i < times.length; i++) {
                    const x = (times[i] / duration) * canvas.width;
                    // Normalize value to [0,1] within [min, max]
                    let norm = max !== min ? (values[i] - min) / (max - min) : 0;
                    norm = Math.max(0, Math.min(1, norm)); // clamp
                    const valY = y + (1 - norm) * height; // high value = top
                    if (i === 0) ctx.moveTo(x, valY);
                    else ctx.lineTo(x, valY);
                }
                ctx.stroke();
            }

            // Border
            ctx.strokeStyle = '#ddd';
            ctx.strokeRect(0, y, canvas.width, height);
        }

        function drawWaveform(waveform, width, totalHeight, height, y) {
            ctx.fillStyle = '#fafafa';
            ctx.fillRect(0, y, width, height);

            ctx.strokeStyle = '#4A90E2';
            ctx.lineWidth = 1;
            ctx.beginPath();
            for (let i = 0; i < waveform.length; i++) {
                const x = (i / waveform.length) * width;
                const wy = y + height / 2 + waveform[i] * (height / 2);
                if (i === 0) ctx.moveTo(x, wy);
                else ctx.lineTo(x, wy);
            }
            ctx.stroke();

            // Baseline
            ctx.strokeStyle = '#999';
            ctx.setLineDash([4,2]);
            ctx.beginPath();
            ctx.moveTo(0, y + height / 2);
            ctx.lineTo(width, y + height / 2);
            ctx.stroke();
            ctx.setLineDash([]);

            ctx.fillStyle = '#000';
            ctx.fillText('Waveform', 10, y + 15);
            ctx.strokeRect(0, y, width, height);
        }

        function renderDescriptorLegend() {
            const container = document.getElementById('descriptor-legend');
            if (!container) return;

            container.innerHTML = '';
            container.style.display = 'flex';
            container.style.flexWrap = 'wrap';
            container.style.gap = '8px';
            container.style.margin = '10px 0';

            allDescriptorKeys.forEach(key => {
                const item = document.createElement('span');
                item.textContent = descriptorMeta[key].label;
                item.style.cursor = 'pointer';
                item.style.padding = '4px 8px';
                item.style.borderRadius = '4px';
                item.style.fontSize = '12px';
                item.style.backgroundColor = visibleDescriptors.has(key) ? '#e3f2fd' : '#f5f5f5';
                item.style.border = `1px solid ${visibleDescriptors.has(key) ? '#2196f3' : '#ccc'}`;
                item.style.color = '#333';

                item.addEventListener('click', () => {
                    if (visibleDescriptors.has(key)) {
                        visibleDescriptors.delete(key);
                    } else {
                        visibleDescriptors.add(key);
                    }
                    drawAnalysis();
                    renderDescriptorLegend();
                });

                container.appendChild(item);
            });
        }
        
        // Display results
        function displayResults(descriptors, elementId) {
            const element = document.getElementById(elementId);
            element.innerHTML = '';
            
            const entries = Object.entries(descriptors);
            if (entries.length === 0) {
                element.innerHTML = '<p>No descriptors computed</p>';
                return;
            }
            
            entries.forEach(([name, value]) => {
                const div = document.createElement('div');
                div.className = 'descriptor';
                div.innerHTML = `
                    <span class="descriptor-name">${name}:</span>
                    <span class="descriptor-value">${value.toFixed(6)}</span>
                `;
                element.appendChild(div);
            });
        }
        
        // Main analysis function
                // Main analysis function
        async function analyzeAudio() {
            if (!isReady) {
                alert('Libraries not ready yet!');
                return;
            }
            
            try {
                // Get parameters
                const frequency = parseFloat(document.getElementById('frequency').value);
                const sampleRate = parseFloat(document.getElementById('sampleRate').value);
                const duration = parseFloat(document.getElementById('duration').value);
                const fftSize = parseInt(document.getElementById('fftSize').value);
                const waveform = document.getElementById('waveform').value;
                
                // Generate audio signal
                console.log(`Generating ${waveform} wave at ${frequency}Hz...`);
                const audioBuffer = generateSignal(waveform, frequency, sampleRate, duration);
                
                // Create Informer instance
                const informer = new InformerLib.Informer(sampleRate, 0.85, fftSize);
                
                // Set buffer and compute time domain descriptors
                informer.setBuffer(audioBuffer);
                informer.computeDescriptors(true, false);
                
                // Get time domain descriptors
                const timeDescriptors = informer.getTimeDescriptors();
                displayResults(timeDescriptors, 'timeResults');
                
                // Compute FFT (now async)
                console.log('Computing FFT...');
                const magnitudes = await computeFFT(audioBuffer, fftSize);
                
                // Set magnitudes and compute frequency domain descriptors
                informer.setMagnitudes(magnitudes);
                informer.computeDescriptors(false, true);
                
                // Get frequency domain descriptors
                const freqDescriptors = informer.getFrequencyDescriptors();
                displayResults(freqDescriptors, 'freqResults');
                
                // Log some key results
                console.log('Analysis complete!');
                console.log('Peak amplitude:', timeDescriptors.peak);
                console.log('RMS:', timeDescriptors.rms);
                console.log('Spectral centroid:', freqDescriptors.centroid, 'Hz');
                console.log('Spectral peak:', freqDescriptors.peak, 'Hz');
                
                // Clean up
                informer.delete();
                
            } catch (error) {
                console.error('Analysis error:', error);
                statusDiv.textContent = 'âœ— Analysis error: ' + error.message;
                statusDiv.className = 'status error';
            }
        }
        
        // Event listener
        analyzeBtn.addEventListener('click', analyzeAudio);
        
        // Allow Enter key to trigger analysis
        document.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && !analyzeBtn.disabled) {
                analyzeAudio();
            }
        });
        
        console.log('FFT implementation loaded');

                audioFileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            statusDiv.textContent = 'âœ“ Decoding audio file...';
            statusDiv.className = 'status ready';

            try {
                const arrayBuffer = await file.arrayBuffer();
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const decoded = await audioContext.decodeAudioData(arrayBuffer);

                // Use only first channel if multichannel
                const channelData = decoded.getChannelData(0);
                const sampleRate = decoded.sampleRate;
                const fftSize = parseInt(document.getElementById('fftSize').value);

                // Run chunked analysis
                await analyzeAudioBuffer(channelData, sampleRate, fftSize);

                // Optional: also run your single-buffer analysis on full file?
                // (You could add a flag or separate button)
            } catch (err) {
                statusDiv.textContent = 'âœ— Error decoding audio: ' + err.message;
                statusDiv.className = 'status error';
                console.error(err);
            }
        });
    </script>
</body>
</html>